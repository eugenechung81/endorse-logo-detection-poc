{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('TkAgg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-3')).expect_partial()\n",
    "\n",
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH + '\\label_map.pbtxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "def get_box(img_path, detections):\n",
    "    img = cv2.imread(img_path)\n",
    "    im_width, im_height, _ = img.shape\n",
    "    [ymin, xmin, ymax, xmax] = detections['detection_boxes'][0]\n",
    "    (left, right, top, bottom) = (xmin * im_width, xmax * im_width, \n",
    "                              ymin * im_height, ymax * im_height)\n",
    "    return (left, right, top, bottom)\n",
    "\n",
    "def process_video(img_path, return_df=True, write_frames=False):\n",
    "    cap = cv2.VideoCapture(img_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)   \n",
    "    rows = []\n",
    "\n",
    "    while True:\n",
    "        ret, img = cap.read()    \n",
    "\n",
    "        current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "        if ret == True:\n",
    "            if current_frame % fps == 0:\n",
    "                # detect \n",
    "                image_np = np.array(img)\n",
    "                input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "                detections = detect_fn(input_tensor)\n",
    "                num_detections = int(detections.pop('num_detections'))\n",
    "                detections = {key: value[0, :num_detections].numpy()\n",
    "                              for key, value in detections.items()}\n",
    "\n",
    "                if return_df:                \n",
    "                    # return as data frame\n",
    "                    current_seconds = current_frame/fps\n",
    "                    if sum(detections['detection_scores'][:5] > 0.8) > 0:\n",
    "                        rows.append({\n",
    "                            'seconds': current_seconds,\n",
    "                            'detected': 1\n",
    "                        })                    \n",
    "                \n",
    "                if write_frames:\n",
    "                    # create bounding box \n",
    "                    detections['num_detections'] = num_detections\n",
    "                    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "                    label_id_offset = 1\n",
    "                    image_np_with_detections = image_np.copy()\n",
    "\n",
    "                    # draw box \n",
    "                    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                                image_np_with_detections,\n",
    "                                detections['detection_boxes'],\n",
    "                                detections['detection_classes']+label_id_offset,\n",
    "                                detections['detection_scores'],\n",
    "                                category_index,\n",
    "                                use_normalized_coordinates=True,\n",
    "                                max_boxes_to_draw=5,\n",
    "                                min_score_thresh=.8,\n",
    "                                agnostic_mode=False)\n",
    "\n",
    "                    # output\n",
    "                    if sum(detections['detection_scores'][:5] > 0.8) > 0:\n",
    "                        file_name = \"frames/\" + img_path.split('.')[0] + '_f' + str(round(current_frame/fps)) + \".jpg\"\n",
    "                        cv2.imwrite(file_name, image_np_with_detections)\n",
    "                        # cv2.imshow('video', image_np_with_detections)\n",
    "                \n",
    "                print('Processing: {} seconds, frame {}'.format(current_frame/fps, current_frame))\n",
    "            if cv2.waitKey(25) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def process_realtime(cap):\n",
    "    while True:\n",
    "        ret, img = cap.read()    \n",
    "\n",
    "        if ret == True:\n",
    "            image_np = np.array(img)\n",
    "\n",
    "            input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "            detections = detect_fn(input_tensor)\n",
    "\n",
    "            num_detections = int(detections.pop('num_detections'))\n",
    "            detections = {key: value[0, :num_detections].numpy()\n",
    "                          for key, value in detections.items()}\n",
    "            detections['num_detections'] = num_detections\n",
    "\n",
    "            # detection_classes should be ints.\n",
    "            detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "            label_id_offset = 1\n",
    "            image_np_with_detections = image_np.copy()\n",
    "\n",
    "            viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                        image_np_with_detections,\n",
    "                        detections['detection_boxes'],\n",
    "                        detections['detection_classes']+label_id_offset,\n",
    "                        detections['detection_scores'],\n",
    "                        category_index,\n",
    "                        use_normalized_coordinates=True,\n",
    "                        max_boxes_to_draw=5,\n",
    "                        min_score_thresh=.8,\n",
    "                        agnostic_mode=False)\n",
    "\n",
    "\n",
    "            cv2.imshow('video', image_np_with_detections)\n",
    "    #         current_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "    #         print('{}: {}'.format(current_frame,current_frame/fps))\n",
    "            if cv2.waitKey(25) == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "def process_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "process_image(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Real Time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"1101763346_clip_s3009_d61.mp4\")\n",
    "process_realtime(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1.0 seconds, frame 60.0\n",
      "Processing: 2.0 seconds, frame 120.0\n",
      "Processing: 3.0 seconds, frame 180.0\n",
      "Processing: 4.0 seconds, frame 240.0\n",
      "Processing: 5.0 seconds, frame 300.0\n",
      "Processing: 6.0 seconds, frame 360.0\n",
      "Processing: 7.0 seconds, frame 420.0\n",
      "Processing: 8.0 seconds, frame 480.0\n",
      "Processing: 9.0 seconds, frame 540.0\n",
      "Processing: 10.0 seconds, frame 600.0\n",
      "Processing: 11.0 seconds, frame 660.0\n",
      "Processing: 12.0 seconds, frame 720.0\n",
      "Processing: 13.0 seconds, frame 780.0\n",
      "Processing: 14.0 seconds, frame 840.0\n",
      "Processing: 15.0 seconds, frame 900.0\n",
      "Processing: 16.0 seconds, frame 960.0\n"
     ]
    }
   ],
   "source": [
    "# img_path = \"1103313375_clip_s14476_d132-cut-1.mp4\"\n",
    "img_path = \"1106871070_clip_s17118_d16.mp4\"\n",
    "df = process_video(img_path, return_df=True, write_frames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1102239417_s0_d3600.csv').drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame([x + 1 for x in range(3600)], columns=['seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2.merge(df, how='left', on='seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['detected'] = df['detected'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('1102239417_s0_d3600_answer_sheet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('1102239417_s0_d3600_answer_sheet.csv').drop(columns=['Unnamed: 0'])\n",
    "# df = df.iloc[:1600]\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.85      0.92      2866\n",
      "         1.0       0.64      1.00      0.78       760\n",
      "\n",
      "    accuracy                           0.88      3626\n",
      "   macro avg       0.82      0.93      0.85      3626\n",
      "weighted avg       0.92      0.88      0.89      3626\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['labeled'], df['detected']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['first_score'] > .9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00        27\n",
      "         1.0       0.96      1.00      0.98       708\n",
      "\n",
      "    accuracy                           0.96       735\n",
      "   macro avg       0.48      0.50      0.49       735\n",
      "weighted avg       0.93      0.96      0.95       735\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df['labeled'], df['detected']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
